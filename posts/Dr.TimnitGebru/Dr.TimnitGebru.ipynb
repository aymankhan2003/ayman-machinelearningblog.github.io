{
 "cells": [
  {
   "cell_type": "raw",
   "id": "4da0b85e-5edb-4aa2-964e-297bdf330b8c",
   "metadata": {},
   "source": [
    "---\n",
    "title: Learning from Timnit Guru\n",
    "author: Ayman Khan\n",
    "date: '2023-04-19'\n",
    "image: \"image.jpg\"\n",
    "description: \"A blog post on the works of Dr. Timnit Guru\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb56f20-7cad-4b73-9e27-677e46bae88a",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7748ba0-d384-4bc2-a880-8dd08cc8d6bd",
   "metadata": {},
   "source": [
    "Dr. Timnit Guru was born and raised in Addis Ababa, Ethiopia. At the young age of 15, she fled to the US to esape the Eritrean-Ethiopian War. Having small living experiences in Ireland, she settled in Sommerville Massachusetts, where she did high school and later would end up studying in Stanford University. \n",
    "\n",
    "Dr. Timnit Gebru is a computer scientist, and an AI researcher, where her works focused a lot on the racial biasness that exists in contemporary systems in the world today. She began her career in engineering at Apple, later transitioning to research at Stanford and Microsoft, and finally co-leading Artificial Intelligence ethics at Google. Dr. Timnit Gebru decided to bring ethical change by publishing research papers, where the higher Google managers were against that idea where she was given an ultimatum which eventually caused her to leave. Now, Timnit Gebru has started her own research company, Black in AI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d339f4-df48-49b1-a539-8f2df0676b2a",
   "metadata": {},
   "source": [
    "# Dr. Gebru's Talk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76f2cd0-b33c-4a67-a2de-f9edafaa25f6",
   "metadata": {},
   "source": [
    "Dr. Gebru's talk focused on the idea of how computer vision algorithms are often biased and unfair, especially when it comes to recognizing people with darker skin tones. She highlights several studies in which algorithms tend to have higher error rates for people of color which eventually lead to serious consequences such as criminal justice and hiring. Gebru emphasizes on the concept of how data is mostly trained to only include white males, where data on people of color tend to be excluded which algorithms cannot analyze hence causing a racial biasness bringing up the question of ethical compliance within many industries as they use these algorithms such as the national police force itself, as Dr. Gebru uses example oh how Batimore police use algorithms that obtains photos of Black protestors which brings a unfair case against them leading to them being arrested for no reason. Facial detection softwares are another instance of biasness which Gebru brings upon emphasis as many companies use facial detections which most black women and people of color in general tend to get mis-identified, and a huge reason for that is the implication that the data set upon the algorithm is being trained lacks the data of people of color as it is filled with a majority of white data. \n",
    "\n",
    "tl;dr: The number of biasness existing in Computer systems and AI is huge due to the lack of collective data in the training data and this causes unethical results in most businesses and human society."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8996e181-26b5-4c14-b531-7f2661c5091c",
   "metadata": {},
   "source": [
    "# Question for Dr. Gebru"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be985550-7284-4645-850b-6eeb8da96d24",
   "metadata": {},
   "source": [
    "1. What actions do you suggest researchers and developers take to address the existing bias issues within computer vision and AI technologies?\n",
    "\n",
    "2. How can we ensure that the development and deployment of computer vision and AI technolgoies are more inclusive and diverse, and they prioritize the needs and well being of all individuals and communities involved?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d37d19-ca30-491e-a915-ede4f71723d5",
   "metadata": {},
   "source": [
    "# Summary of Dr.Gebru's Talk at Middlebury"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a969a53-938e-44c8-8fff-d008041f7ac0",
   "metadata": {},
   "source": [
    "Dr. Gebru's lecture focused on the intersections of eugenics, transhumanism, and the advancement of Artificial General Intelligence (AGI). She emphasized that the desire for AGI development stems from eugenics, which sought to improve \"human stock\" through genetics. TESCREAL ideologies associated with AGI envision a future in which humans merge with machines to transcend biological limitations rather than simply improving humanity.\n",
    "\n",
    "Dr. Gebru, on the other hand, expressed reservations about who would benefit from AGI. While AGI promises a utopia, she wonders if the benefits will be limited to a select few or extend to the entire population. Large AI companies currently have the ability to develop and train AI models without adequately compensating the individuals whose data is used or the labor involved. Exploitative practices, such as the use of low-wage labor from developing countries, have already been documented.\n",
    "\n",
    "The fear is that AGI will replace jobs while benefiting only a small percentage of the population, primarily AI companies. Unlike in the past, when technological advancements were eventually made available to the majority, the unique nature of AGI raises concerns that widespread benefits may not be realized. Benefit concentration must be limited because a small portion of the population cannot continue to benefit while the majority does not.\n",
    "\n",
    "Dr. Gebru's lecture was empowering, emphasizing the ethical concerns and potential negative consequences of AGI. She exemplified how the development of such technologies can take an ethical turn. The talk sparked further interest in the field of computer science, emphasizing the importance of future developers and researchers being aware of the potential consequences of their work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82f7212-1c9e-4aa8-890c-a8f70143b431",
   "metadata": {},
   "source": [
    "# Reflection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7853856-04e6-4aae-b6c0-123529a176d3",
   "metadata": {},
   "source": [
    "Overall, Dr. Gebru presented some intriguing ideas about AI and how the intersections of eugenics and transhumanism are playing a role in creating bias among companies in the advancement of AI. Some of her statements are critical because she throws a lot based on her opinions, and her explanations aren't always supported by logical facts. Even with these preconceptions, Dr. Gebru made significant points as she spoke and revealed biases within these large corporations that affect a large percentage of the population. She emphasizes the topic of AGI and how it only benefits a small percentage of people, which is caused by the data sets acquired by these companies, which excludes many people, resulting in bias formation. Many people may find Dr. Gebru's talk to be a bit personal due to her use of many opinions, but she raises a lot of good points, which helps me think about social responsibility in the world of Big Data, Machine Learning, and Artificial Intelligence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml-0451]",
   "language": "python",
   "name": "conda-env-ml-0451-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
