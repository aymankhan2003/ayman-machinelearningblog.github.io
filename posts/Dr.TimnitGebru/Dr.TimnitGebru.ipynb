{
 "cells": [
  {
   "cell_type": "raw",
   "id": "4da0b85e-5edb-4aa2-964e-297bdf330b8c",
   "metadata": {},
   "source": [
    "---\n",
    "title: Learning from Timnit Guru\n",
    "author: Ayman Khan\n",
    "date: '2023-04-19'\n",
    "image: \"image.jpg\"\n",
    "description: \"A blog post on the works of Dr. Timnit Guru\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb56f20-7cad-4b73-9e27-677e46bae88a",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7748ba0-d384-4bc2-a880-8dd08cc8d6bd",
   "metadata": {},
   "source": [
    "Dr. Timnit Guru was born and raised in Addis Ababa, Ethiopia. At the young age of 15, she fled to the US to esape the Eritrean-Ethiopian War. Having small living experiences in Ireland, she settled in Sommerville Massachusetts, where she did high school and later would end up studying in Stanford University. \n",
    "\n",
    "Dr. Timnit Gebru is a computer scientist, and an AI researcher, where her works focused a lot on the racial biasness that exists in contemporary systems in the world today. She began her career in engineering at Apple, later transitioning to research at Stanford and Microsoft, and finally co-leading Artificial Intelligence ethics at Google. Dr. Timnit Gebru decided to bring ethical change by publishing research papers, where the higher Google managers were against that idea where she was given an ultimatum which eventually caused her to leave. Now, Timnit Gebru has started her own research company, Black in AI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d339f4-df48-49b1-a539-8f2df0676b2a",
   "metadata": {},
   "source": [
    "# Dr. Gebru's Talk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76f2cd0-b33c-4a67-a2de-f9edafaa25f6",
   "metadata": {},
   "source": [
    "Dr. Gebru's talk focused on the idea of how computer vision algorithms are often biased and unfair, especially when it comes to recognizing people with darker skin tones. She highlights several studies in which algorithms tend to have higher error rates for people of color which eventually lead to serious consequences such as criminal justice and hiring. Gebru emphasizes on the concept of how data is mostly trained to only include white males, where data on people of color tend to be excluded which algorithms cannot analyze hence causing a racial biasness bringing up the question of ethical compliance within many industries as they use these algorithms such as the national police force itself, as Dr. Gebru uses example oh how Batimore police use algorithms that obtains photos of Black protestors which brings a unfair case against them leading to them being arrested for no reason. Facial detection softwares are another instance of biasness which Gebru brings upon emphasis as many companies use facial detections which most black women and people of color in general tend to get mis-identified, and a huge reason for that is the implication that the data set upon the algorithm is being trained lacks the data of people of color as it is filled with a majority of white data. \n",
    "\n",
    "tl;dr: The number of biasness existing in Computer systems and AI is huge due to the lack of collective data in the training data and this causes unethical results in most businesses and human society."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8996e181-26b5-4c14-b531-7f2661c5091c",
   "metadata": {},
   "source": [
    "# Question for Dr. Gebru"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be985550-7284-4645-850b-6eeb8da96d24",
   "metadata": {},
   "source": [
    "1. What actions do you suggest researchers and developers take to address the existing bias issues within computer vision and AI technologies?\n",
    "\n",
    "2. How can we ensure that the development and deployment of computer vision and AI technolgoies are more inclusive and diverse, and they prioritize the needs and well being of all individuals and communities involved?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml-0451]",
   "language": "python",
   "name": "conda-env-ml-0451-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
